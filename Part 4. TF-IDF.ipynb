{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('data/labeledTrainData.tsv', \n",
    "                    header=0, delimiter='\\t', quoting=3)\n",
    "test = pd.read_csv('data/testData.tsv', \n",
    "                   header=0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>전처리는 HTML만 제거</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from preprocessing import preprocessing\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_words(raw_review):\n",
    "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
    "    return review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review_clean'] = [review_to_words(s) for s in train['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['review_clean'] = [review_to_words(s) for s in test['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"With all this stuff going down at the moment ...\n",
       "1    \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2    \"The film starts with a manager (Nicholas Bell...\n",
       "3    \"It must be assumed that those who praised thi...\n",
       "4    \"Superbly trashy and wondrously unpretentious ...\n",
       "5    \"I dont know why people think this is such a b...\n",
       "6    \"This movie could have been very good, but com...\n",
       "7    \"I watched this video at a friend's house. I'm...\n",
       "8    \"A friend of mine bought this film for £1, and...\n",
       "9    \"This movie is full of references. Like \\\"Mad ...\n",
       "Name: review_clean, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review_clean'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train['review_clean']\n",
    "x_test = test['review_clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TF-IDF</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\trevor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=90000, min_df=2,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None,\n",
       "        vocabulary={'anthropotomical', 'diabolicalness', 'evilproof', 'parthenogeny', 'inadvertence', 'decahedral', 'irreverend', 'interopercle', 'guildhall', 'bellyflaught', 'Cayubaban', 'untrickable', 'hydranth', 'unchasteness', 'running', 'unfanatical', 'vagabondismus', 'aswoon', 'Horatio', 'countertail'...cosovereign', 'pantler', 'forecited', 'enanthema', 'coercionary', 'kerflap', 'porrect', 'dyingness'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import words\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'word',\n",
    "                            lowercase = True,\n",
    "                            tokenizer = None,\n",
    "                            preprocessor = None,\n",
    "                            stop_words = 'english',\n",
    "                            min_df = 2, #토큰이 나타날 최소 문서 개수.\n",
    "                            ngram_range=(1,3),\n",
    "                            vocabulary = set(words.words()),\n",
    "                            max_features = 90000)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=90000, min_df=2,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "       ...('tfidf', TfidfTransformer(norm='l2', smooth_idf=False, sublinear_tf=False,\n",
       "         use_idf=True))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TfidfTransformer() -> norm = ('L1', 'L2')가 있고. L2가 디폴트. L2 : 벡터의 각 원소의 제곱의 합이 1이 되도록 만드는것. L1은 벡터의 각 원소의 절댓값의 합이 1\n",
    "# smooth_idf = false : 피처를 만들 때 0으로 나오는 항목에 대해 작은 값을 더해서(스무딩을 해서) 피처를 만들지 아니면 그냥 생성할지.\n",
    "# use_idf = True : TF를 사용할지 아니면 TFIDF를 사용할지.\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('tfidf', TfidfTransformer(smooth_idf = False)),\n",
    "])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(float(n_samples) / df) + 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train_tfidf_vector = pipeline.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'Aani',\n",
       " 'Aaron',\n",
       " 'Aaronic',\n",
       " 'Aaronical',\n",
       " 'Aaronite',\n",
       " 'Aaronitic',\n",
       " 'Aaru',\n",
       " 'Ab',\n",
       " 'Ababdeh']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print(len(vocab))\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(float(n_samples) / df) + 1.0\n"
     ]
    }
   ],
   "source": [
    "x_test_tfidf_vector = pipeline.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A [[ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>Aani</th>\n",
       "      <th>Aaron</th>\n",
       "      <th>Aaronic</th>\n",
       "      <th>Aaronical</th>\n",
       "      <th>Aaronite</th>\n",
       "      <th>Aaronitic</th>\n",
       "      <th>Aaru</th>\n",
       "      <th>Ab</th>\n",
       "      <th>Ababdeh</th>\n",
       "      <th>...</th>\n",
       "      <th>zymotechnical</th>\n",
       "      <th>zymotechnics</th>\n",
       "      <th>zymotechny</th>\n",
       "      <th>zymotic</th>\n",
       "      <th>zymotically</th>\n",
       "      <th>zymotize</th>\n",
       "      <th>zymotoxic</th>\n",
       "      <th>zymurgy</th>\n",
       "      <th>zythem</th>\n",
       "      <th>zythum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 235892 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A  Aani  Aaron  Aaronic  Aaronical  Aaronite  Aaronitic  Aaru   Ab  \\\n",
       "0  0.0   0.0    0.0      0.0        0.0       0.0        0.0   0.0  0.0   \n",
       "\n",
       "   Ababdeh   ...    zymotechnical  zymotechnics  zymotechny  zymotic  \\\n",
       "0      0.0   ...              0.0           0.0         0.0      0.0   \n",
       "\n",
       "   zymotically  zymotize  zymotoxic  zymurgy  zythem  zythum  \n",
       "0          0.0       0.0        0.0      0.0     0.0     0.0  \n",
       "\n",
       "[1 rows x 235892 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dist = np.sum(x_train_tfidf_vector, axis=0)\n",
    "\n",
    "for tag, count in zip(vocab,dist):\n",
    "    print(tag, count)\n",
    "\n",
    "pd.DataFrame(dist, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=2018, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100, n_jobs=-1, random_state=2018)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = forest.fit(x_train_tfidf_vector, train['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cross Validation 교차 검증</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "\n",
    "score = np.mean(cross_val_score(forest, x_train_tfidf_vector, train['sentiment'], cv = k_fold, scoring = 'roc_auc', n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.92068'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:,.5f}'.format(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = forest.predict(x_test_tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rst[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  sentiment\n",
       "0  \"12311_10\"          1\n",
       "1    \"8348_2\"          0\n",
       "2    \"5828_4\"          0\n",
       "3    \"7186_2\"          0\n",
       "4   \"12128_7\"          1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame(data = {'id':test['id'], 'sentiment':rst})\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    12688\n",
       "0    12312\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentiment = output['sentiment'].value_counts()\n",
    "print(output_sentiment[0] - output_sentiment[1])\n",
    "output_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('data/tutorial_4_tfidf_{0:.5f}.csv'.format(score), index=False, quoting=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
